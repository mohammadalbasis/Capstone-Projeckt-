{"cells":[{"cell_type":"markdown","metadata":{"id":"FvZy_z3zIhh-"},"source":["## LSTM\n","\n","Here we will perform sentiment analysis using LSTM in Keras. Keras has a built-in IMDb movie reviews dataset that we can use."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"TLQOL6aFIhiE","executionInfo":{"status":"ok","timestamp":1687507427287,"user_tz":-330,"elapsed":458,"user":{"displayName":"Nisarg Gandhewar","userId":"00173707501276252012"}}},"outputs":[],"source":["from keras.datasets import imdb"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XBqGrCWNIhiI","executionInfo":{"status":"ok","timestamp":1687507430919,"user_tz":-330,"elapsed":2917,"user":{"displayName":"Nisarg Gandhewar","userId":"00173707501276252012"}},"outputId":"08cc56e2-ec02-4faa-f0be-4d5b4d3a1386"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded dataset with 25000 training samples, 25000 test samples\n"]}],"source":["vocabulary_size = 5000\n","\n","(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n","print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"]},{"cell_type":"markdown","metadata":{"id":"Z5VUaowJIhiL"},"source":[" Inspect a sample review and its label"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G0sV0f6TIhiM","executionInfo":{"status":"ok","timestamp":1687507430921,"user_tz":-330,"elapsed":67,"user":{"displayName":"Nisarg Gandhewar","userId":"00173707501276252012"}},"outputId":"9c90c906-0386-47f0-ede3-2b1dd52f467d"},"outputs":[{"output_type":"stream","name":"stdout","text":["---Sample Review---\n","[1, 2, 365, 1234, 5, 1156, 354, 11, 14, 2, 2, 7, 1016, 2, 2, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 2, 2, 1117, 1831, 2, 5, 4831, 26, 6, 2, 4183, 17, 369, 37, 215, 1345, 143, 2, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 2, 2, 63, 271, 6, 196, 96, 949, 4121, 4, 2, 7, 4, 2212, 2436, 819, 63, 47, 77, 2, 180, 6, 227, 11, 94, 2494, 2, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 2, 99, 76, 23, 2, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901]\n","---label---\n","1\n"]}],"source":["print('---Sample Review---')\n","print(X_train[6])\n","\n","print('---label---')\n","print(y_train[6])"]},{"cell_type":"markdown","metadata":{"id":"ms8vhKqGIhiN"},"source":["Map word IDs back to words"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d5-QKxDIIhiO","executionInfo":{"status":"ok","timestamp":1687507430922,"user_tz":-330,"elapsed":64,"user":{"displayName":"Nisarg Gandhewar","userId":"00173707501276252012"}},"outputId":"26b96dce-36be-49ae-f73c-13f77ced0692"},"outputs":[{"output_type":"stream","name":"stdout","text":["---review with words---\n","['the', 'and', 'full', 'involving', 'to', 'impressive', 'boring', 'this', 'as', 'and', 'and', 'br', 'villain', 'and', 'and', 'need', 'has', 'of', 'costumes', 'b', 'message', 'to', 'may', 'of', 'props', 'this', 'and', 'and', 'concept', 'issue', 'and', 'to', \"god's\", 'he', 'is', 'and', 'unfolds', 'movie', 'women', 'like', \"isn't\", 'surely', \"i'm\", 'and', 'to', 'toward', 'in', \"here's\", 'for', 'from', 'did', 'having', 'because', 'very', 'quality', 'it', 'is', 'and', 'and', 'really', 'book', 'is', 'both', 'too', 'worked', 'carl', 'of', 'and', 'br', 'of', 'reviewer', 'closer', 'figure', 'really', 'there', 'will', 'and', 'things', 'is', 'far', 'this', 'make', 'mistakes', 'and', 'was', \"couldn't\", 'of', 'few', 'br', 'of', 'you', 'to', \"don't\", 'female', 'than', 'place', 'she', 'to', 'was', 'between', 'that', 'nothing', 'and', 'movies', 'get', 'are', 'and', 'br', 'yes', 'female', 'just', 'its', 'because', 'many', 'br', 'of', 'overly', 'to', 'descent', 'people', 'time', 'very', 'bland']\n","---label---\n","1\n"]}],"source":["# Retrieves a dict mapping words to their index in the IMDB dataset.\n","# The word index dictionary. Keys are word strings, values are their index.\n","word2id = imdb.get_word_index()\n","id2word = {i: word for word, i in word2id.items()}\n","print('---review with words---')\n","print([id2word.get(i, ' ') for i in X_train[6]])\n","\n","print('---label---')\n","print(y_train[6])"]},{"cell_type":"markdown","metadata":{"id":"wnfv_I4zIhiP"},"source":["Maximum review length and minimum review length"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fo-ND5MiIhiQ","executionInfo":{"status":"ok","timestamp":1687507430924,"user_tz":-330,"elapsed":59,"user":{"displayName":"Nisarg Gandhewar","userId":"00173707501276252012"}},"outputId":"f0b9d5ed-bffe-4219-a069-bbfe37e73595"},"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum review length: 2697\n"]}],"source":["print('Maximum review length: {}'.format(\n","len(max((X_train + X_test), key=len))))"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3vi3jQZIhiR","executionInfo":{"status":"ok","timestamp":1687507431505,"user_tz":-330,"elapsed":632,"user":{"displayName":"Nisarg Gandhewar","userId":"00173707501276252012"}},"outputId":"ccdb59f9-6544-466a-9b98-2a608c4a76b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Minimum review length: 14\n"]}],"source":["print('Minimum review length: {}'.format(\n","len(min((X_test + X_test), key=len))))"]},{"cell_type":"markdown","metadata":{"id":"KnKKr3nYIhiT"},"source":["### Pad sequences\n","\n","In order to feed this data into our LSTM, all input documents must have the same length. We will limit the maximum review length to max_words by truncating longer reviews and padding shorter reviews with a null value (0). We can accomplish this using the pad_sequences() function in Keras. For now, set max_words to 500."]},{"cell_type":"code","execution_count":26,"metadata":{"id":"vz7JVDivIhiU","executionInfo":{"status":"ok","timestamp":1687507432065,"user_tz":-330,"elapsed":564,"user":{"displayName":"Nisarg Gandhewar","userId":"00173707501276252012"}}},"outputs":[],"source":["from keras.utils import pad_sequences\n","\n","max_words = 500\n","X_train = pad_sequences(X_train, maxlen=max_words)\n","X_test = pad_sequences(X_test, maxlen=max_words)"]},{"cell_type":"markdown","metadata":{"id":"eAyb8cDoIhiV"},"source":["### Design an LSTM model for sentiment analysis\n","\n","Build our model architecture in the code cell below. We have imported some layers from Keras that you might need but feel free to use any other layers / transformations you like.\n","\n","Remember that our input is a sequence of words (technically, integer word IDs) of maximum length = max_words, and our output is a binary sentiment label (0 or 1)."]},{"cell_type":"code","execution_count":32,"metadata":{"id":"JNSRJRP7IhiW","executionInfo":{"status":"ok","timestamp":1687508174808,"user_tz":-330,"elapsed":411,"user":{"displayName":"Nisarg Gandhewar","userId":"00173707501276252012"}}},"outputs":[],"source":["from keras import Sequential\n","from keras.layers import Embedding, LSTM, Dense, Dropout\n","\n","embedding_size=32\n","model=Sequential()\n","model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n","model.add(LSTM(100))\n","model.add(Dense(1, activation='sigmoid'))\n"]},{"cell_type":"markdown","metadata":{"id":"GGvER4jLIhiX"},"source":["To summarize, our model is a simple LSTM model with 1 embedding, 1 LSTM and 1 dense layers."]},{"cell_type":"markdown","metadata":{"id":"UnwVEy-3IhiX"},"source":["### Train and evaluate our model\n","\n","We first need to compile our model by specifying the loss function and optimizer we want to use while training, as well as any evaluation metrics we'd like to measure. Specify the approprate parameters, including at least one metric 'accuracy'."]},{"cell_type":"code","execution_count":28,"metadata":{"id":"0oNTK-6bIhiY","executionInfo":{"status":"ok","timestamp":1687507432067,"user_tz":-330,"elapsed":8,"user":{"displayName":"Nisarg Gandhewar","userId":"00173707501276252012"}}},"outputs":[],"source":["model.compile(loss='binary_crossentropy',\n","             optimizer='adam',\n","             metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"j7QjR5iBIhiZ"},"source":["Once compiled, we can kick off the training process. There are two important training parameters that we have to specify - batch size and number of training epochs, which together with our model architecture determine the total training time.\n","\n"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hsBbzb2WIhia","executionInfo":{"status":"ok","timestamp":1687507916589,"user_tz":-330,"elapsed":483899,"user":{"displayName":"Nisarg Gandhewar","userId":"00173707501276252012"}},"outputId":"ab83edb9-e935-46a0-dbfe-7b8a6ee44da0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","390/390 [==============================] - 164s 416ms/step - loss: 0.4666 - accuracy: 0.7725 - val_loss: 0.2760 - val_accuracy: 0.9062\n","Epoch 2/3\n","390/390 [==============================] - 160s 411ms/step - loss: 0.3082 - accuracy: 0.8772 - val_loss: 0.2470 - val_accuracy: 0.9062\n","Epoch 3/3\n","390/390 [==============================] - 160s 409ms/step - loss: 0.2633 - accuracy: 0.8989 - val_loss: 0.2127 - val_accuracy: 0.9375\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f89649efac0>"]},"metadata":{},"execution_count":29}],"source":["batch_size = 64\n","num_epochs = 3\n","\n","X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n","X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n","\n","model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)"]},{"cell_type":"markdown","metadata":{"id":"lbxP7SLbIhib"},"source":["scores[1] will correspond to accuracy if we pass metrics=['accuracy']"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RhL3bcwWIhib","executionInfo":{"status":"ok","timestamp":1687508014226,"user_tz":-330,"elapsed":44268,"user":{"displayName":"Nisarg Gandhewar","userId":"00173707501276252012"}},"outputId":"62759814-9c43-43bb-8de0-a8921d24b052"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy: 0.8693600296974182\n"]}],"source":["# Testing\n","scores = model.evaluate(X_test, y_test, verbose=0)\n","print('Test accuracy:', scores[1])"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"gLWoNh1RIhic","executionInfo":{"status":"ok","timestamp":1687507960841,"user_tz":-330,"elapsed":61,"user":{"displayName":"Nisarg Gandhewar","userId":"00173707501276252012"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}