{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip3 install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how Logistic Regression acts with 5 techniques:\n",
    "1. Standardization of Numerical Variables\n",
    "2. Encoding of Categorical Variables\n",
    "3. Data Imbalance\n",
    "4. Colinearity\n",
    "5. Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from snape.make_dataset import make_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out snape [here](https://github.com/mbernico/snape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(categorical_features=True,\n",
    "             balanced=True, \n",
    "             correlated_features=False, \n",
    "             missing_values=False,\n",
    "             dataset_size=12000):\n",
    "    \n",
    "    if categorical_features:\n",
    "        label_list = []\n",
    "        N_CATEGORICAL = 4\n",
    "        for i in range(N_CATEGORICAL):\n",
    "            num_classes = np.random.randint(2, 10)\n",
    "            labels = list(np.arange(num_classes))\n",
    "            labels = [f'str_{i}' for i in labels]\n",
    "            label_list.append(labels)\n",
    "            \n",
    "    if correlated_features:\n",
    "        N_REDUNDANT = 1\n",
    "        N_REPEATED = 1\n",
    "        N_INFORMATIVE = 8 - N_REDUNDANT - N_REPEATED\n",
    "    \n",
    "    conf = {\n",
    "        \"type\": \"classification\",\n",
    "        \"n_classes\": 2,\n",
    "        \"n_samples\": dataset_size,\n",
    "        \"n_features\": 8,\n",
    "        \"out_path\": \"./\",\n",
    "        \"output\": \"my_dataset\",\n",
    "        \"n_informative\": N_INFORMATIVE if correlated_features else 8,\n",
    "        \"n_repeated\": N_REPEATED if correlated_features else 0,\n",
    "        \"n_redundant\": N_REDUNDANT if correlated_features else 0,\n",
    "        \"n_clusters\": 2,\n",
    "        \"weights\": [0.5, 0.5] if balanced else [0.9, 0.1],\n",
    "        \"pct_missing\": 0.70 if missing_values else 0.00,\n",
    "        \"n_categorical\": N_CATEGORICAL if categorical_features else 0,\n",
    "        \"random_seed\":42,\n",
    "        \"label_list\":label_list if categorical_features else []\n",
    "    }\n",
    "\n",
    "    make_dataset(config=conf)\n",
    "    df = pd.read_csv('my_dataset_train.csv')\n",
    "    \n",
    "    label = 'y'\n",
    "    categorical_features = [col for col in df.columns if (df[col].dtype==object) & (col != label)]\n",
    "    numerical_features = [col for col in df.columns if (col not in categorical_features) & (col != label)]\n",
    "    \n",
    "    return df, label, categorical_features, numerical_features\n",
    "\n",
    "def evaluation(pipeline, X, y):\n",
    "    y_predict_proba = pipeline.predict_proba(X)[:, 1]\n",
    "    return{\n",
    "        'auc': roc_auc_score(y, y_predict_proba),\n",
    "        'pr-auc': average_precision_score(y, y_predict_proba)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Standardiazation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Warning: n_repeated not in configuration, defaulting to 0\n",
      "Warning: n_clusters_per_class not in configuration, defaulting to 2\n",
      "Warning: effective_rank not in configuration, defaulting to None\n",
      "Warning: tail_strength not in configuration, defaulting to 0.5\n",
      "Warning: noise not in configuration, defaulting to 0.0\n",
      "Warning: shuffle not in configuration, defaulting to True\n",
      "Creating Classification Dataset...\n",
      "Warning: insert_dollar not in configuration, defaulting to 'No'\n",
      "Warning: insert_percent not in configuration, defaulting to 'No'\n",
      "Warning: star_schema not in configuration, defaulting to 'No'\n",
      "Writing Train/Test Datasets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96000.000000</td>\n",
       "      <td>96000.000000</td>\n",
       "      <td>96000.000000</td>\n",
       "      <td>96000.000000</td>\n",
       "      <td>96000.000000</td>\n",
       "      <td>96000.000000</td>\n",
       "      <td>96000.000000</td>\n",
       "      <td>96000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.645228</td>\n",
       "      <td>2.244024</td>\n",
       "      <td>1.045137</td>\n",
       "      <td>2.714882</td>\n",
       "      <td>-0.020220</td>\n",
       "      <td>-0.004654</td>\n",
       "      <td>-1.536356</td>\n",
       "      <td>-4.197611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.209578</td>\n",
       "      <td>8.602877</td>\n",
       "      <td>1.733465</td>\n",
       "      <td>9.096954</td>\n",
       "      <td>11.988777</td>\n",
       "      <td>4.719140</td>\n",
       "      <td>2.810519</td>\n",
       "      <td>15.886376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-35.268886</td>\n",
       "      <td>-34.012532</td>\n",
       "      <td>-7.229214</td>\n",
       "      <td>-35.163348</td>\n",
       "      <td>-49.768093</td>\n",
       "      <td>-20.945358</td>\n",
       "      <td>-13.822828</td>\n",
       "      <td>-78.725850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-5.758226</td>\n",
       "      <td>-3.452518</td>\n",
       "      <td>-0.106077</td>\n",
       "      <td>-3.561230</td>\n",
       "      <td>-8.276808</td>\n",
       "      <td>-3.241806</td>\n",
       "      <td>-3.394866</td>\n",
       "      <td>-15.068164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.709702</td>\n",
       "      <td>2.393561</td>\n",
       "      <td>1.051668</td>\n",
       "      <td>2.789480</td>\n",
       "      <td>0.106544</td>\n",
       "      <td>-0.308207</td>\n",
       "      <td>-1.546129</td>\n",
       "      <td>-3.386493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.515567</td>\n",
       "      <td>8.106976</td>\n",
       "      <td>2.192445</td>\n",
       "      <td>9.022244</td>\n",
       "      <td>8.357289</td>\n",
       "      <td>3.115309</td>\n",
       "      <td>0.302129</td>\n",
       "      <td>7.250865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25.206965</td>\n",
       "      <td>42.072130</td>\n",
       "      <td>9.851492</td>\n",
       "      <td>43.896856</td>\n",
       "      <td>43.189071</td>\n",
       "      <td>21.426677</td>\n",
       "      <td>13.305723</td>\n",
       "      <td>62.477698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x0            x1            x2            x3            x4  \\\n",
       "count  96000.000000  96000.000000  96000.000000  96000.000000  96000.000000   \n",
       "mean      -1.645228      2.244024      1.045137      2.714882     -0.020220   \n",
       "std        6.209578      8.602877      1.733465      9.096954     11.988777   \n",
       "min      -35.268886    -34.012532     -7.229214    -35.163348    -49.768093   \n",
       "25%       -5.758226     -3.452518     -0.106077     -3.561230     -8.276808   \n",
       "50%       -1.709702      2.393561      1.051668      2.789480      0.106544   \n",
       "75%        2.515567      8.106976      2.192445      9.022244      8.357289   \n",
       "max       25.206965     42.072130      9.851492     43.896856     43.189071   \n",
       "\n",
       "                 x5            x6            x7  \n",
       "count  96000.000000  96000.000000  96000.000000  \n",
       "mean      -0.004654     -1.536356     -4.197611  \n",
       "std        4.719140      2.810519     15.886376  \n",
       "min      -20.945358    -13.822828    -78.725850  \n",
       "25%       -3.241806     -3.394866    -15.068164  \n",
       "50%       -0.308207     -1.546129     -3.386493  \n",
       "75%        3.115309      0.302129      7.250865  \n",
       "max       21.426677     13.305723     62.477698  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, label, categorical_features, numerical_features = get_data(categorical_features=False, dataset_size=120000)\n",
    "df[numerical_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "X_train, y_train = train_df[categorical_features + numerical_features], train_df[label]\n",
    "X_test, y_test = test_df[categorical_features + numerical_features], test_df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 1 of 1) Processing clf, total=   0.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.8148784308322949, 'pr-auc': 0.818032430163559}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('clf', clf)\n",
    "], verbose=True)\n",
    "\n",
    "pipeline.fit(X_train[numerical_features], y_train)\n",
    "evaluation(pipeline, X_test[numerical_features], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=   0.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.8148798631692816, 'pr-auc': 0.8180303186841142}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = [([n], [StandardScaler()]) for n in numerical_features]\n",
    "mapper = DataFrameMapper(num, df_out=True)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', mapper),\n",
    "    ('clf', clf)\n",
    "], verbose=True)\n",
    "\n",
    "pipeline.fit(X_train[numerical_features], y_train)\n",
    "evaluation(pipeline, X_test[numerical_features], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**\n",
    "- No need to scale for logistic regression accuracy. But convergence is faster. [More info here](https://stats.stackexchange.com/questions/48360/is-standardization-needed-before-fitting-logistic-regression#:~:text=3%20Answers&text=Standardization%20isn't%20required%20for,the%20technique%20used%20for%20optimization.&text=Otherwise%2C%20you%20can%20run%20your,standardization%20treatment%20on%20the%20features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need numeric encoding for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Warning: n_repeated not in configuration, defaulting to 0\n",
      "Warning: n_clusters_per_class not in configuration, defaulting to 2\n",
      "Warning: effective_rank not in configuration, defaulting to None\n",
      "Warning: tail_strength not in configuration, defaulting to 0.5\n",
      "Warning: noise not in configuration, defaulting to 0.0\n",
      "Warning: shuffle not in configuration, defaulting to True\n",
      "Creating Classification Dataset...\n",
      "Creating Categorical Features...\n",
      "Warning: insert_dollar not in configuration, defaulting to 'No'\n",
      "Warning: insert_percent not in configuration, defaulting to 'No'\n",
      "Warning: star_schema not in configuration, defaulting to 'No'\n",
      "Writing Train/Test Datasets\n"
     ]
    }
   ],
   "source": [
    "df, label, categorical_features, numerical_features = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=   0.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.8304397645792462, 'pr-auc': 0.80297861579569}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "X_train, y_train = train_df[categorical_features + numerical_features], train_df[label]\n",
    "X_test, y_test = test_df[categorical_features + numerical_features], test_df[label]\n",
    "\n",
    "num = [([n], [SimpleImputer()]) for n in numerical_features]\n",
    "cat = [([c], [OneHotEncoder()]) for c in categorical_features]\n",
    "mapper = DataFrameMapper(cat + num, df_out=True)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', mapper),\n",
    "    ('clf', clf)\n",
    "], verbose=True)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "evaluation(pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8640</th>\n",
       "      <th>8641</th>\n",
       "      <th>8642</th>\n",
       "      <th>8643</th>\n",
       "      <th>8644</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x1_x0_str_0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1_x0_str_1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1_x0_str_2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1_x0_str_3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1_x0_str_4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1_x0_str_5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3_x0_str_0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3_x0_str_1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3_x0_str_2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3_x0_str_3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3_x0_str_4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x6_x0_str_0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x6_x0_str_1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x6_x0_str_2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x6_x0_str_3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x6_x0_str_4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x6_x0_str_5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x6_x0_str_6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x6_x0_str_7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7_x0_str_0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7_x0_str_1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7_x0_str_2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7_x0_str_3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7_x0_str_4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7_x0_str_5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7_x0_str_6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x0</th>\n",
       "      <td>-10.703380</td>\n",
       "      <td>-4.189989</td>\n",
       "      <td>10.965457</td>\n",
       "      <td>11.707606</td>\n",
       "      <td>-10.140494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>-12.941344</td>\n",
       "      <td>-14.909158</td>\n",
       "      <td>-21.448502</td>\n",
       "      <td>-6.947473</td>\n",
       "      <td>-36.795258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>-6.464533</td>\n",
       "      <td>7.366311</td>\n",
       "      <td>3.887812</td>\n",
       "      <td>-8.306792</td>\n",
       "      <td>-7.842345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>-0.328846</td>\n",
       "      <td>-11.833629</td>\n",
       "      <td>13.592603</td>\n",
       "      <td>10.200299</td>\n",
       "      <td>-3.358164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  8640       8641       8642       8643       8644\n",
       "x1_x0_str_0   0.000000   0.000000   0.000000   0.000000   0.000000\n",
       "x1_x0_str_1   0.000000   0.000000   0.000000   0.000000   0.000000\n",
       "x1_x0_str_2   1.000000   0.000000   0.000000   1.000000   1.000000\n",
       "x1_x0_str_3   0.000000   1.000000   1.000000   0.000000   0.000000\n",
       "x1_x0_str_4   0.000000   0.000000   0.000000   0.000000   0.000000\n",
       "x1_x0_str_5   0.000000   0.000000   0.000000   0.000000   0.000000\n",
       "x3_x0_str_0   0.000000   0.000000   0.000000   0.000000   0.000000\n",
       "x3_x0_str_1   0.000000   0.000000   1.000000   0.000000   0.000000\n",
       "x3_x0_str_2   0.000000   1.000000   0.000000   1.000000   1.000000\n",
       "x3_x0_str_3   1.000000   0.000000   0.000000   0.000000   0.000000\n",
       "x3_x0_str_4   0.000000   0.000000   0.000000   0.000000   0.000000\n",
       "x6_x0_str_0   0.000000   0.000000   0.000000   0.000000   0.000000\n",
       "x6_x0_str_1   0.000000   0.000000   0.000000   0.000000   0.000000\n",
       "x6_x0_str_2   0.000000   0.000000   0.000000   1.000000   0.000000\n",
       "x6_x0_str_3   1.000000   1.000000   0.000000   0.000000   0.000000\n",
       "x6_x0_str_4   0.000000   0.000000   1.000000   0.000000   1.000000\n",
       "x6_x0_str_5   0.000000   0.000000   0.000000   0.000000   0.000000\n",
       "x6_x0_str_6   0.000000   0.000000   0.000000   0.000000   0.000000\n",
       "x6_x0_str_7   0.000000   0.000000   0.000000   0.000000   0.000000\n",
       "x7_x0_str_0   0.000000   0.000000   0.000000   0.000000   0.000000\n",
       "x7_x0_str_1   0.000000   0.000000   0.000000   0.000000   1.000000\n",
       "x7_x0_str_2   0.000000   0.000000   0.000000   0.000000   0.000000\n",
       "x7_x0_str_3   1.000000   0.000000   1.000000   1.000000   0.000000\n",
       "x7_x0_str_4   0.000000   0.000000   0.000000   0.000000   0.000000\n",
       "x7_x0_str_5   0.000000   1.000000   0.000000   0.000000   0.000000\n",
       "x7_x0_str_6   0.000000   0.000000   0.000000   0.000000   0.000000\n",
       "x0          -10.703380  -4.189989  10.965457  11.707606 -10.140494\n",
       "x2          -12.941344 -14.909158 -21.448502  -6.947473 -36.795258\n",
       "x4           -6.464533   7.366311   3.887812  -8.306792  -7.842345\n",
       "x5           -0.328846 -11.833629  13.592603  10.200299  -3.358164"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_X_test = mapper.transform(X_test)\n",
    "preprocessed_X_test.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=   0.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.8194499904512231, 'pr-auc': 0.7996358755932719}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = [([n], [SimpleImputer()]) for n in numerical_features]\n",
    "cat = [([c], [OrdinalEncoder()]) for c in categorical_features]\n",
    "mapper = DataFrameMapper(cat + num, df_out=True)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', mapper),\n",
    "    ('clf', clf)\n",
    "], verbose=True)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "evaluation(pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9000</th>\n",
       "      <th>9001</th>\n",
       "      <th>9002</th>\n",
       "      <th>9003</th>\n",
       "      <th>9004</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feat_5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_6</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_8</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_1</th>\n",
       "      <td>-0.068768</td>\n",
       "      <td>0.425899</td>\n",
       "      <td>1.930354</td>\n",
       "      <td>1.157980</td>\n",
       "      <td>-1.304169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_2</th>\n",
       "      <td>-1.222878</td>\n",
       "      <td>0.293660</td>\n",
       "      <td>1.729959</td>\n",
       "      <td>-0.716538</td>\n",
       "      <td>1.169799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_3</th>\n",
       "      <td>-0.714906</td>\n",
       "      <td>1.509702</td>\n",
       "      <td>-0.429593</td>\n",
       "      <td>-0.708234</td>\n",
       "      <td>-0.304866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_4</th>\n",
       "      <td>-0.823643</td>\n",
       "      <td>1.997845</td>\n",
       "      <td>0.105752</td>\n",
       "      <td>-0.953579</td>\n",
       "      <td>0.690543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            9000      9001      9002      9003      9004\n",
       "feat_5  1.000000  3.000000  6.000000  0.000000  5.000000\n",
       "feat_6  2.000000  3.000000  0.000000  1.000000  0.000000\n",
       "feat_7  0.000000  2.000000  6.000000  4.000000  1.000000\n",
       "feat_8  4.000000  7.000000  7.000000  0.000000  5.000000\n",
       "feat_1 -0.068768  0.425899  1.930354  1.157980 -1.304169\n",
       "feat_2 -1.222878  0.293660  1.729959 -0.716538  1.169799\n",
       "feat_3 -0.714906  1.509702 -0.429593 -0.708234 -0.304866\n",
       "feat_4 -0.823643  1.997845  0.105752 -0.953579  0.690543"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_X_test = mapper.transform(X_test)\n",
    "preprocessed_X_test.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**: \n",
    "- `OrdinalEncoding` works when relationships exist between categorical variables (size, weather). Otherwise, prefer `OneHotEncoding`\n",
    "- `OneHotEncoding` takes up space. Hence more training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if the training data isn't balanced?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Warning: n_clusters_per_class not in configuration, defaulting to 2\n",
      "Warning: effective_rank not in configuration, defaulting to None\n",
      "Warning: tail_strength not in configuration, defaulting to 0.5\n",
      "Warning: noise not in configuration, defaulting to 0.0\n",
      "Warning: shuffle not in configuration, defaulting to True\n",
      "Creating Classification Dataset...\n",
      "Creating Categorical Features...\n",
      "Warning: insert_dollar not in configuration, defaulting to 'No'\n",
      "Warning: insert_percent not in configuration, defaulting to 'No'\n",
      "Warning: star_schema not in configuration, defaulting to 'No'\n",
      "Writing Train/Test Datasets\n"
     ]
    }
   ],
   "source": [
    "df, label, categorical_features, numerical_features = get_data(balanced=False)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "X_train, y_train = train_df[categorical_features + numerical_features], train_df[label]\n",
    "X_test, y_test = test_df[categorical_features + numerical_features], test_df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8599\n",
       "1    1001\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[label].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.7869518716577542, 'pr-auc': 0.39239809756882393}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = [([n], [SimpleImputer()]) for n in numerical_features]\n",
    "cat = [([c], [OrdinalEncoder()]) for c in categorical_features]\n",
    "mapper = DataFrameMapper(cat + num, df_out=True)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', mapper),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "evaluation(pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_proba = pipeline.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10815533327119523"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_proba.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Warning: n_repeated not in configuration, defaulting to 0\n",
      "Warning: n_clusters_per_class not in configuration, defaulting to 2\n",
      "Warning: effective_rank not in configuration, defaulting to None\n",
      "Warning: tail_strength not in configuration, defaulting to 0.5\n",
      "Warning: noise not in configuration, defaulting to 0.0\n",
      "Warning: shuffle not in configuration, defaulting to True\n",
      "Creating Classification Dataset...\n",
      "Creating Categorical Features...\n",
      "Warning: insert_dollar not in configuration, defaulting to 'No'\n",
      "Warning: insert_percent not in configuration, defaulting to 'No'\n",
      "Warning: star_schema not in configuration, defaulting to 'No'\n",
      "Writing Train/Test Datasets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.7949023220244715, 'pr-auc': 0.7742073929744453}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, label, categorical_features, numerical_features = get_data(balanced=True)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "X_train, y_train = train_df[categorical_features + numerical_features], train_df[label]\n",
    "X_test, y_test = test_df[categorical_features + numerical_features], test_df[label]\n",
    "\n",
    "num = [([n], [SimpleImputer()]) for n in numerical_features]\n",
    "cat = [([c], [OrdinalEncoder()]) for c in categorical_features]\n",
    "mapper = DataFrameMapper(cat + num, df_out=True)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', mapper),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "evaluation(pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4994547544271453"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "y_predict_proba.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with unbalanced data by over weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Warning: n_clusters_per_class not in configuration, defaulting to 2\n",
      "Warning: effective_rank not in configuration, defaulting to None\n",
      "Warning: tail_strength not in configuration, defaulting to 0.5\n",
      "Warning: noise not in configuration, defaulting to 0.0\n",
      "Warning: shuffle not in configuration, defaulting to True\n",
      "Creating Classification Dataset...\n",
      "Creating Categorical Features...\n",
      "Warning: insert_dollar not in configuration, defaulting to 'No'\n",
      "Warning: insert_percent not in configuration, defaulting to 'No'\n",
      "Warning: star_schema not in configuration, defaulting to 'No'\n",
      "Writing Train/Test Datasets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.8113720373994346, 'pr-auc': 0.30360454333181025}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, label, categorical_features, numerical_features = get_data(balanced=False)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "X_train, y_train = train_df[categorical_features + numerical_features], train_df[label]\n",
    "X_test, y_test = test_df[categorical_features + numerical_features], test_df[label]\n",
    "\n",
    "num = [([n], [SimpleImputer()]) for n in numerical_features]\n",
    "cat = [([c], [OrdinalEncoder()]) for c in categorical_features]\n",
    "mapper = DataFrameMapper(cat + num, df_out=True)\n",
    "\n",
    "clf = LogisticRegression(class_weight='balanced')\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', mapper),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "evaluation(pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**:\n",
    "- Having an unbalanced dataset doesn't harm accuracy, but harms precision-recall metrics of the positive class.\n",
    "- This is mostly due to lower predicted probability values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Warning: n_clusters_per_class not in configuration, defaulting to 2\n",
      "Warning: effective_rank not in configuration, defaulting to None\n",
      "Warning: tail_strength not in configuration, defaulting to 0.5\n",
      "Warning: noise not in configuration, defaulting to 0.0\n",
      "Warning: shuffle not in configuration, defaulting to True\n",
      "Creating Classification Dataset...\n",
      "Warning: insert_dollar not in configuration, defaulting to 'No'\n",
      "Warning: insert_percent not in configuration, defaulting to 'No'\n",
      "Warning: star_schema not in configuration, defaulting to 'No'\n",
      "Writing Train/Test Datasets\n"
     ]
    }
   ],
   "source": [
    "df, label, categorical_features, numerical_features = get_data(categorical_features=False, correlated_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.9194931452103352, 'pr-auc': 0.8982012865508728}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "X_train, y_train = train_df[categorical_features + numerical_features], train_df[label]\n",
    "X_test, y_test = test_df[categorical_features + numerical_features], test_df[label]\n",
    "\n",
    "num = [([n], [SimpleImputer()]) for n in numerical_features]\n",
    "mapper = DataFrameMapper(num, df_out=True)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', mapper),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "evaluation(pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1345.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 10 Apr 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:31:47</td>     <th>  Log-Likelihood:    </th> <td> -3420.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8640</td>      <th>  AIC:               </th> <td>   6855.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8633</td>      <th>  BIC:               </th> <td>   6904.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.5906</td> <td>    0.006</td> <td>  104.957</td> <td> 0.000</td> <td>    0.580</td> <td>    0.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0</th>    <td>   -0.0043</td> <td>    0.000</td> <td>  -20.533</td> <td> 0.000</td> <td>   -0.005</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0335</td> <td>    0.002</td> <td>   19.438</td> <td> 0.000</td> <td>    0.030</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0447</td> <td>    0.001</td> <td>   43.084</td> <td> 0.000</td> <td>    0.043</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0076</td> <td>    0.000</td> <td>  -20.533</td> <td> 0.000</td> <td>   -0.008</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0142</td> <td>    0.001</td> <td>  -27.006</td> <td> 0.000</td> <td>   -0.015</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0125</td> <td>    0.000</td> <td>   45.550</td> <td> 0.000</td> <td>    0.012</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.0017</td> <td>    0.002</td> <td>   -0.997</td> <td> 0.319</td> <td>   -0.005</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0270</td> <td>    0.001</td> <td>   28.009</td> <td> 0.000</td> <td>    0.025</td> <td>    0.029</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>341.439</td> <th>  Durbin-Watson:     </th> <td>   2.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 353.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.467</td>  <th>  Prob(JB):          </th> <td>2.20e-77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.670</td>  <th>  Cond. No.          </th> <td>1.54e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.5e-26. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.483\n",
       "Model:                            OLS   Adj. R-squared:                  0.483\n",
       "Method:                 Least Squares   F-statistic:                     1345.\n",
       "Date:                Sat, 10 Apr 2021   Prob (F-statistic):               0.00\n",
       "Time:                        14:31:47   Log-Likelihood:                -3420.3\n",
       "No. Observations:                8640   AIC:                             6855.\n",
       "Df Residuals:                    8633   BIC:                             6904.\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.5906      0.006    104.957      0.000       0.580       0.602\n",
       "x0            -0.0043      0.000    -20.533      0.000      -0.005      -0.004\n",
       "x1             0.0335      0.002     19.438      0.000       0.030       0.037\n",
       "x2             0.0447      0.001     43.084      0.000       0.043       0.047\n",
       "x3            -0.0076      0.000    -20.533      0.000      -0.008      -0.007\n",
       "x4            -0.0142      0.001    -27.006      0.000      -0.015      -0.013\n",
       "x5             0.0125      0.000     45.550      0.000       0.012       0.013\n",
       "x6            -0.0017      0.002     -0.997      0.319      -0.005       0.002\n",
       "x7             0.0270      0.001     28.009      0.000       0.025       0.029\n",
       "==============================================================================\n",
       "Omnibus:                      341.439   Durbin-Watson:                   2.027\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              353.022\n",
       "Skew:                          -0.467   Prob(JB):                     2.20e-77\n",
       "Kurtosis:                       2.670   Cond. No.                     1.54e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.5e-26. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "preprocessed_X_train = mapper.transform(X_train)\n",
    "preprocessed_X_train = sm.add_constant(preprocessed_X_train)\n",
    "results = sm.OLS(y_train, preprocessed_X_train).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0, inf\n",
      "x1, inf\n",
      "x2, inf\n",
      "x3, inf\n",
      "x4, inf\n",
      "x5, inf\n",
      "x6, inf\n",
      "x7, inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/statsmodels/stats/outliers_influence.py:193: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "for column in numerical_features:\n",
    "    print(f\"\"\"{column}, {variance_inflation_factor(\n",
    "                                preprocessed_X_train.values, \n",
    "                                list(preprocessed_X_train.columns).index(column))}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.132384</td>\n",
       "      <td>-0.097071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.035234</td>\n",
       "      <td>-0.162566</td>\n",
       "      <td>0.346866</td>\n",
       "      <td>0.567626</td>\n",
       "      <td>-0.000326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>0.132384</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029556</td>\n",
       "      <td>0.132384</td>\n",
       "      <td>0.143301</td>\n",
       "      <td>-0.434811</td>\n",
       "      <td>0.091475</td>\n",
       "      <td>0.211035</td>\n",
       "      <td>-0.020443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>-0.097071</td>\n",
       "      <td>0.029556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.097071</td>\n",
       "      <td>0.272320</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>-0.077077</td>\n",
       "      <td>-0.546263</td>\n",
       "      <td>0.275935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.132384</td>\n",
       "      <td>-0.097071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.035234</td>\n",
       "      <td>-0.162566</td>\n",
       "      <td>0.346866</td>\n",
       "      <td>0.567626</td>\n",
       "      <td>-0.000326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>-0.035234</td>\n",
       "      <td>0.143301</td>\n",
       "      <td>0.272320</td>\n",
       "      <td>-0.035234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.144259</td>\n",
       "      <td>0.144366</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>-0.008192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>-0.162566</td>\n",
       "      <td>-0.434811</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>-0.162566</td>\n",
       "      <td>-0.144259</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120178</td>\n",
       "      <td>0.083330</td>\n",
       "      <td>0.544321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x6</th>\n",
       "      <td>0.346866</td>\n",
       "      <td>0.091475</td>\n",
       "      <td>-0.077077</td>\n",
       "      <td>0.346866</td>\n",
       "      <td>0.144366</td>\n",
       "      <td>0.120178</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.649177</td>\n",
       "      <td>0.308940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7</th>\n",
       "      <td>0.567626</td>\n",
       "      <td>0.211035</td>\n",
       "      <td>-0.546263</td>\n",
       "      <td>0.567626</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.083330</td>\n",
       "      <td>0.649177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>-0.000326</td>\n",
       "      <td>-0.020443</td>\n",
       "      <td>0.275935</td>\n",
       "      <td>-0.000326</td>\n",
       "      <td>-0.008192</td>\n",
       "      <td>0.544321</td>\n",
       "      <td>0.308940</td>\n",
       "      <td>0.071201</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x0        x1        x2        x3        x4        x5        x6  \\\n",
       "x0  1.000000  0.132384 -0.097071  1.000000 -0.035234 -0.162566  0.346866   \n",
       "x1  0.132384  1.000000  0.029556  0.132384  0.143301 -0.434811  0.091475   \n",
       "x2 -0.097071  0.029556  1.000000 -0.097071  0.272320  0.001597 -0.077077   \n",
       "x3  1.000000  0.132384 -0.097071  1.000000 -0.035234 -0.162566  0.346866   \n",
       "x4 -0.035234  0.143301  0.272320 -0.035234  1.000000 -0.144259  0.144366   \n",
       "x5 -0.162566 -0.434811  0.001597 -0.162566 -0.144259  1.000000  0.120178   \n",
       "x6  0.346866  0.091475 -0.077077  0.346866  0.144366  0.120178  1.000000   \n",
       "x7  0.567626  0.211035 -0.546263  0.567626  0.314752  0.083330  0.649177   \n",
       "y  -0.000326 -0.020443  0.275935 -0.000326 -0.008192  0.544321  0.308940   \n",
       "\n",
       "          x7         y  \n",
       "x0  0.567626 -0.000326  \n",
       "x1  0.211035 -0.020443  \n",
       "x2 -0.546263  0.275935  \n",
       "x3  0.567626 -0.000326  \n",
       "x4  0.314752 -0.008192  \n",
       "x5  0.083330  0.544321  \n",
       "x6  0.649177  0.308940  \n",
       "x7  1.000000  0.071201  \n",
       "y   0.071201  1.000000  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with removing perfectly multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.9194974891835068, 'pr-auc': 0.8982064967028441}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features = ['x0', 'x1', 'x2', 'x4', 'x5', 'x6', 'x7'] # remove x3\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "X_train, y_train = train_df[categorical_features + numerical_features], train_df[label]\n",
    "X_test, y_test = test_df[categorical_features + numerical_features], test_df[label]\n",
    "\n",
    "num = [([n], [SimpleImputer()]) for n in numerical_features]\n",
    "mapper = DataFrameMapper(num, df_out=True)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', mapper),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "evaluation(pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1345.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 10 Apr 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:37:17</td>     <th>  Log-Likelihood:    </th> <td> -3420.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8640</td>      <th>  AIC:               </th> <td>   6855.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8633</td>      <th>  BIC:               </th> <td>   6904.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.5906</td> <td>    0.006</td> <td>  104.957</td> <td> 0.000</td> <td>    0.580</td> <td>    0.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0</th>    <td>   -0.0172</td> <td>    0.001</td> <td>  -20.533</td> <td> 0.000</td> <td>   -0.019</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0357</td> <td>    0.002</td> <td>   19.852</td> <td> 0.000</td> <td>    0.032</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0438</td> <td>    0.001</td> <td>   43.527</td> <td> 0.000</td> <td>    0.042</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0138</td> <td>    0.001</td> <td>  -26.951</td> <td> 0.000</td> <td>   -0.015</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0127</td> <td>    0.000</td> <td>   47.049</td> <td> 0.000</td> <td>    0.012</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.0005</td> <td>    0.002</td> <td>   -0.294</td> <td> 0.769</td> <td>   -0.004</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0260</td> <td>    0.001</td> <td>   28.111</td> <td> 0.000</td> <td>    0.024</td> <td>    0.028</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>341.439</td> <th>  Durbin-Watson:     </th> <td>   2.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 353.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.467</td>  <th>  Prob(JB):          </th> <td>2.20e-77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.670</td>  <th>  Cond. No.          </th> <td>1.67e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is  9e-27. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.483\n",
       "Model:                            OLS   Adj. R-squared:                  0.483\n",
       "Method:                 Least Squares   F-statistic:                     1345.\n",
       "Date:                Sat, 10 Apr 2021   Prob (F-statistic):               0.00\n",
       "Time:                        14:37:17   Log-Likelihood:                -3420.3\n",
       "No. Observations:                8640   AIC:                             6855.\n",
       "Df Residuals:                    8633   BIC:                             6904.\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.5906      0.006    104.957      0.000       0.580       0.602\n",
       "x0            -0.0172      0.001    -20.533      0.000      -0.019      -0.016\n",
       "x1             0.0357      0.002     19.852      0.000       0.032       0.039\n",
       "x2             0.0438      0.001     43.527      0.000       0.042       0.046\n",
       "x4            -0.0138      0.001    -26.951      0.000      -0.015      -0.013\n",
       "x5             0.0127      0.000     47.049      0.000       0.012       0.013\n",
       "x6            -0.0005      0.002     -0.294      0.769      -0.004       0.003\n",
       "x7             0.0260      0.001     28.111      0.000       0.024       0.028\n",
       "==============================================================================\n",
       "Omnibus:                      341.439   Durbin-Watson:                   2.027\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              353.022\n",
       "Skew:                          -0.467   Prob(JB):                     2.20e-77\n",
       "Kurtosis:                       2.670   Cond. No.                     1.67e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is  9e-27. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_X_train = mapper.transform(X_train)\n",
    "preprocessed_X_train = sm.add_constant(preprocessed_X_train)\n",
    "results = sm.OLS(y_train, preprocessed_X_train).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0, inf\n",
      "x1, inf\n",
      "x2, inf\n",
      "x4, inf\n",
      "x5, inf\n",
      "x6, inf\n",
      "x7, inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/statsmodels/stats/outliers_influence.py:193: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    }
   ],
   "source": [
    "for column in numerical_features:\n",
    "    print(f\"\"\"{column}, {variance_inflation_factor(\n",
    "                                preprocessed_X_train.values, \n",
    "                                list(preprocessed_X_train.columns).index(column))}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing feature with perfect multicolinearity:\n",
    "- Improves interpretability of the coefficients (like `x0` here)\n",
    "- Logistic Regression doesn't lose performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.9194974891835068, 'pr-auc': 0.8982064967028441}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features = ['x0', 'x1', 'x2', 'x4', 'x5', 'x7'] # remove x3, x6\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "X_train, y_train = train_df[categorical_features + numerical_features], train_df[label]\n",
    "X_test, y_test = test_df[categorical_features + numerical_features], test_df[label]\n",
    "\n",
    "num = [([n], [SimpleImputer()]) for n in numerical_features]\n",
    "mapper = DataFrameMapper(num, df_out=True)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', mapper),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "evaluation(pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1345.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 10 Apr 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:38:52</td>     <th>  Log-Likelihood:    </th> <td> -3420.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8640</td>      <th>  AIC:               </th> <td>   6855.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8633</td>      <th>  BIC:               </th> <td>   6904.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.5906</td> <td>    0.006</td> <td>  104.957</td> <td> 0.000</td> <td>    0.580</td> <td>    0.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0</th>    <td>   -0.0169</td> <td>    0.001</td> <td>  -17.744</td> <td> 0.000</td> <td>   -0.019</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0366</td> <td>    0.005</td> <td>    7.684</td> <td> 0.000</td> <td>    0.027</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0434</td> <td>    0.001</td> <td>   40.460</td> <td> 0.000</td> <td>    0.041</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0137</td> <td>    0.001</td> <td>  -25.047</td> <td> 0.000</td> <td>   -0.015</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0128</td> <td>    0.000</td> <td>   33.306</td> <td> 0.000</td> <td>    0.012</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0256</td> <td>    0.001</td> <td>   27.862</td> <td> 0.000</td> <td>    0.024</td> <td>    0.027</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>341.439</td> <th>  Durbin-Watson:     </th> <td>   2.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 353.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.467</td>  <th>  Prob(JB):          </th> <td>2.20e-77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.670</td>  <th>  Cond. No.          </th> <td>    30.1</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.483\n",
       "Model:                            OLS   Adj. R-squared:                  0.483\n",
       "Method:                 Least Squares   F-statistic:                     1345.\n",
       "Date:                Sat, 10 Apr 2021   Prob (F-statistic):               0.00\n",
       "Time:                        14:38:52   Log-Likelihood:                -3420.3\n",
       "No. Observations:                8640   AIC:                             6855.\n",
       "Df Residuals:                    8633   BIC:                             6904.\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.5906      0.006    104.957      0.000       0.580       0.602\n",
       "x0            -0.0169      0.001    -17.744      0.000      -0.019      -0.015\n",
       "x1             0.0366      0.005      7.684      0.000       0.027       0.046\n",
       "x2             0.0434      0.001     40.460      0.000       0.041       0.045\n",
       "x4            -0.0137      0.001    -25.047      0.000      -0.015      -0.013\n",
       "x5             0.0128      0.000     33.306      0.000       0.012       0.014\n",
       "x7             0.0256      0.001     27.862      0.000       0.024       0.027\n",
       "==============================================================================\n",
       "Omnibus:                      341.439   Durbin-Watson:                   2.027\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              353.022\n",
       "Skew:                          -0.467   Prob(JB):                     2.20e-77\n",
       "Kurtosis:                       2.670   Cond. No.                         30.1\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_X_train = mapper.transform(X_train)\n",
    "preprocessed_X_train = sm.add_constant(preprocessed_X_train)\n",
    "results = sm.OLS(y_train, preprocessed_X_train).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0, 4.358204798860465\n",
      "x1, 1.8526871839909662\n",
      "x2, 5.622338237184614\n",
      "x4, 4.123960180952725\n",
      "x5, 2.6095687697415917\n",
      "x7, 10.922197872534808\n"
     ]
    }
   ],
   "source": [
    "for column in numerical_features:\n",
    "    print(f\"\"\"{column}, {variance_inflation_factor(\n",
    "                                preprocessed_X_train.values, \n",
    "                                list(preprocessed_X_train.columns).index(column))}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing `x6`, we didn't lose explainability nor performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove x7 with high VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.8916873729387849, 'pr-auc': 0.858019953399781}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features = ['x0', 'x1', 'x2', 'x4', 'x5'] # remove x3, x6, x7\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "X_train, y_train = train_df[categorical_features + numerical_features], train_df[label]\n",
    "X_test, y_test = test_df[categorical_features + numerical_features], test_df[label]\n",
    "\n",
    "num = [([n], [SimpleImputer()]) for n in numerical_features]\n",
    "mapper = DataFrameMapper(num, df_out=True)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', mapper),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "evaluation(pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1338.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 10 Apr 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:40:42</td>     <th>  Log-Likelihood:    </th> <td> -3792.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8640</td>      <th>  AIC:               </th> <td>   7596.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8634</td>      <th>  BIC:               </th> <td>   7639.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.6395</td> <td>    0.006</td> <td>  114.609</td> <td> 0.000</td> <td>    0.629</td> <td>    0.650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0</th>    <td>    0.0063</td> <td>    0.000</td> <td>   12.833</td> <td> 0.000</td> <td>    0.005</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.1125</td> <td>    0.004</td> <td>   27.526</td> <td> 0.000</td> <td>    0.104</td> <td>    0.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0166</td> <td>    0.000</td> <td>   33.605</td> <td> 0.000</td> <td>    0.016</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0007</td> <td>    0.000</td> <td>   -2.314</td> <td> 0.021</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0204</td> <td>    0.000</td> <td>   73.414</td> <td> 0.000</td> <td>    0.020</td> <td>    0.021</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>381.662</td> <th>  Durbin-Watson:     </th> <td>   2.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 330.564</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.412</td>  <th>  Prob(JB):          </th> <td>1.66e-72</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.511</td>  <th>  Cond. No.          </th> <td>    26.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.437\n",
       "Model:                            OLS   Adj. R-squared:                  0.436\n",
       "Method:                 Least Squares   F-statistic:                     1338.\n",
       "Date:                Sat, 10 Apr 2021   Prob (F-statistic):               0.00\n",
       "Time:                        14:40:42   Log-Likelihood:                -3792.2\n",
       "No. Observations:                8640   AIC:                             7596.\n",
       "Df Residuals:                    8634   BIC:                             7639.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.6395      0.006    114.609      0.000       0.629       0.650\n",
       "x0             0.0063      0.000     12.833      0.000       0.005       0.007\n",
       "x1             0.1125      0.004     27.526      0.000       0.104       0.121\n",
       "x2             0.0166      0.000     33.605      0.000       0.016       0.018\n",
       "x4            -0.0007      0.000     -2.314      0.021      -0.001      -0.000\n",
       "x5             0.0204      0.000     73.414      0.000       0.020       0.021\n",
       "==============================================================================\n",
       "Omnibus:                      381.662   Durbin-Watson:                   2.031\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              330.564\n",
       "Skew:                          -0.412   Prob(JB):                     1.66e-72\n",
       "Kurtosis:                       2.511   Cond. No.                         26.7\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_X_train = mapper.transform(X_train)\n",
    "preprocessed_X_train = sm.add_constant(preprocessed_X_train)\n",
    "results = sm.OLS(y_train, preprocessed_X_train).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0, 1.0434492528061576\n",
      "x1, 1.2487373171729157\n",
      "x2, 1.089610333638892\n",
      "x4, 1.1174255753042328\n",
      "x5, 1.2630916367080673\n"
     ]
    }
   ],
   "source": [
    "for column in numerical_features:\n",
    "    print(f\"\"\"{column}, {variance_inflation_factor(\n",
    "                                preprocessed_X_train.values, \n",
    "                                list(preprocessed_X_train.columns).index(column))}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing `x7`:\n",
    "- Helped explainability \n",
    "- Negatively impacted performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remedy: Add polynomial terms, Try other models that capture more complex interactions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Warning: n_clusters_per_class not in configuration, defaulting to 2\n",
      "Warning: effective_rank not in configuration, defaulting to None\n",
      "Warning: tail_strength not in configuration, defaulting to 0.5\n",
      "Warning: noise not in configuration, defaulting to 0.0\n",
      "Warning: shuffle not in configuration, defaulting to True\n",
      "Creating Classification Dataset...\n",
      "Creating Categorical Features...\n",
      "Warning: insert_dollar not in configuration, defaulting to 'No'\n",
      "Warning: insert_percent not in configuration, defaulting to 'No'\n",
      "Warning: star_schema not in configuration, defaulting to 'No'\n",
      "Writing Train/Test Datasets\n"
     ]
    }
   ],
   "source": [
    "df, label, categorical_features, numerical_features = get_data(missing_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-431bbbcde037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m ])\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumerical_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumerical_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1344\u001b[0m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[1;32m   1345\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m                                    accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1347\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 664\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n\u001b[0;32m--> 106\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m    107\u001b[0m             )\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "X_train, y_train = train_df[categorical_features + numerical_features], train_df[label]\n",
    "X_test, y_test = test_df[categorical_features + numerical_features], test_df[label]\n",
    "\n",
    "num = [([n], [SimpleImputer()]) for n in numerical_features]\n",
    "mapper = DataFrameMapper(num, df_out=True)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "pipeline = Pipeline([\n",
    "    #('preprocess', mapper),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train[numerical_features], y_train)\n",
    "evaluation(pipeline, X_test[numerical_features], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.7473034970984109, 'pr-auc': 0.676792150205654}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "X_train, y_train = train_df[categorical_features + numerical_features], train_df[label]\n",
    "X_test, y_test = test_df[categorical_features + numerical_features], test_df[label]\n",
    "\n",
    "num = [([n], [SimpleImputer()]) for n in numerical_features] # Impute values\n",
    "mapper = DataFrameMapper(num, df_out=True)\n",
    "                                                                                                                                                           \n",
    "clf = LogisticRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', mapper),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train[numerical_features], y_train)\n",
    "evaluation(pipeline, X_test[numerical_features], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**\n",
    "- Logistic Regression can't handle missing values. Best Imupute with mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Let's see how Logistic Regression acts with 5 techniques:\n",
    "1. **Standardization of Numerical Variables**\n",
    "    - Performance doesn't necessarily improve. But convergence is faster during training\n",
    "2. **Encoding of Categorical Variables**\n",
    "    - We can use ordinal encoding if the categories are related (size). Otherwise, use one hot encoding\n",
    "3. **Data Imbalance**\n",
    "    - Perform overweighting of the minor class and undersampling of the major class\n",
    "4. **Colinearity**\n",
    "    - remove features which exhibit perfect multicolinearity\n",
    "    - try different modeling strategies to ensure the model is capturing non-linear interactions\n",
    "5. **Missing Values**\n",
    "    - Impute with mean (or a constant value). This is problem specific"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
